{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file includes the code for preparing the DHS data. \n",
    "As mentioned earlier, the code fits well for the DHS file, but given the nondisclosure I signed to obtain the data, I am not allowed to share it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dtafile = file.DTA # Adjust as necessary\n",
    "df = pd.read_stata(dtafile)\n",
    "df.tail()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Missing values replacements (similar to Stata 'replace')\n",
    "# Replace values using a dictionary\n",
    "replace_dict = {\n",
    "    'hw70': {9996: np.nan, 9997: np.nan, 9998: np.nan, 9999: np.nan},\n",
    "    'hw71': {9996: np.nan, 9997: np.nan, 9998: np.nan, 9999: np.nan},\n",
    "    'hw72': {9996: np.nan, 9997: np.nan, 9998: np.nan, 9999: np.nan},\n",
    "    'hw2': {999: np.nan},\n",
    "    'hw3': {9999: np.nan},\n",
    "    'v437': {9999: np.nan},\n",
    "    'v438': {9999: np.nan},\n",
    "    'v131': {99: np.nan},\n",
    "    'v463z': {9: np.nan},\n",
    "    'm4': {96: np.nan, 97: np.nan, 98: np.nan, 99: np.nan, 94: 0}, # still breastfeeding, 0: never breastfed\n",
    "    'h10': {8: np.nan, 9: np.nan},\n",
    "    'v104': {97: np.nan, 98: np.nan, 99: np.nan}\n",
    "}\n",
    "\n",
    "df.replace(replace_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Handle breastfeeding and respondent residence separately\n",
    "df.loc[df['m4'] == 95, 'm4'] = df['hw1']  # breastfeeding: assign age in months of child\n",
    "df.loc[df['v104'] == 95, 'v104'] = df['v012']  # respondent has always lived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create new variables using a dictionary for assignment\n",
    "df = df.assign(\n",
    "    resage=df['v012'],\n",
    "    educlv=df['v106'],\n",
    "    educyr=df['v107'],\n",
    "    agehh=df['v152'],\n",
    "    totchrbn=df['v201'],\n",
    "    childnum=df['b16'],\n",
    "    breastfd=df['m4'],\n",
    "    reswgt=df['v437'] / 10,\n",
    "    resht=df['v438'] / 10,\n",
    "    childage=df['hw1'],\n",
    "    vaccination=(df['h10'] == 1).astype(int),  # boolean to int conversion\n",
    "    \n",
    "    weight=df['hw2'] / 10,\n",
    "    height=df['hw3'] / 10,\n",
    "    hta=pd.to_numeric(df['hw70'], errors='coerce') / 100,\n",
    "    wta=pd.to_numeric(df['hw71'], errors='coerce') / 100,\n",
    "    wtht=pd.to_numeric(df['hw72'], errors='coerce') / 100,\n",
    "    \n",
    "    male=(df['b4'] == 'male').astype(int),\n",
    "    prebrthint=df['b11'],\n",
    "    brthwgt=pd.to_numeric(df['m19'], errors='coerce') / 100,\n",
    "    urban=(df['v025'] == 'urban').astype(int),\n",
    "    electricity=(df['v119'] == 'yes').astype(int),\n",
    "    hlthcntr=(df['v394'] == 'yes').astype(int),\n",
    "    notsmoking=(df['v463z'] == 'yes, does not use tobacco').astype(int),\n",
    "    ethnicity=df['v131'],\n",
    "    femalehh=(df['v151'] == 'female').astype(int),\n",
    "    mariageage=df['v511'],\n",
    "    wealth=df['v190'],\n",
    "    # Wealth quintiles\n",
    "    prst=(df['v190'] == 'poorest').astype(int),\n",
    "    poorer=(df['v190'] == 'poorer').astype(int),\n",
    "    mddl=(df['v190'] == 'middle').astype(int),\n",
    "    rchr=(df['v190'] == 'richer').astype(int),\n",
    "    rchst=(df['v190'] == 'richest').astype(int),\n",
    "    #Indicators for born during and affected region\n",
    "    bn = (df['b3'] >= 1266) & (df['b3'] <= 1271),\n",
    "    ar = (df['v024'] == 'southern') | (df['v024'] == 'western'), \n",
    "    # generate indicator for those born in the affected regions (southern & western)\n",
    "    sbreak = (df['hw1']>23)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    wasting=(df['wtht'] < -2).astype(int),  # wasting indicator\n",
    "    underweight=(df['wta'] < -2).astype(int),  # underweight indicator\n",
    "    stunting=(df['hta'] < -2).astype(int),  # stunting indicator\n",
    "    # Education levels\n",
    "    noeduc=(df['educlv'] == 'no education').astype(int),\n",
    "    prmryeduc=(df['educlv'] == 'primary').astype(int),\n",
    "    seceduc=(df['educlv'] == 'secondary').astype(int),\n",
    "    hghreduc=(df['educlv'] == 'higher').astype(int),\n",
    "    # Interaction terms\n",
    "    bnar = df['bn'] & df['ar'],\n",
    "    car=pd.to_numeric(df['childage'], errors='coerce') * df['ar'],\n",
    "    cmale=pd.to_numeric(df['childage'], errors='coerce') * df['male'],\n",
    "    cprebrthint=pd.to_numeric(df['childage'], errors='coerce') * df['prebrthint'],\n",
    "    cchildnum=pd.to_numeric(df['childage'], errors='coerce') * pd.to_numeric(df['childnum'], errors='coerce'),\n",
    "    cbreastfd=pd.to_numeric(df['childage'], errors='coerce') * pd.to_numeric(df['breastfd'], errors='coerce'),\n",
    "    sbreak=(df['childage'] > 23).astype(int),\n",
    "    sar=(df['childage'] > 23).astype(int) * df['ar'],\n",
    "    lchildage=np.log(pd.to_numeric(df['childage'], errors='coerce')),\n",
    "    lar=np.log(pd.to_numeric(df['childage'], errors='coerce')) * df['ar'],\n",
    "    lmale=np.log(pd.to_numeric(df['childage'], errors='coerce')) * df['male'],\n",
    "    cwealth=pd.to_numeric(df['childage'], errors='coerce') * pd.to_numeric(df['wealth'], errors='coerce'),\n",
    "    swealth=pd.to_numeric(df['sbreak'], errors='coerce') * pd.to_numeric(df['wealth'], errors='coerce'),\n",
    "    wgt=df['v005'] / 1000000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure the columns are in numeric format before performing comparisons\n",
    "df = df.assign(\n",
    "    v104=pd.to_numeric(df['v104'], errors='coerce'),\n",
    "    hw13=pd.to_numeric(df['hw13'], errors='coerce'),\n",
    "    b16=pd.to_numeric(df['b16'], errors='coerce'),\n",
    "    v447=pd.to_numeric(df['v447'], errors='coerce')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Now perform the filtering\n",
    "df = df[(df['v104'] != 96)]\n",
    "df = df[(df['b16'] != 0)]\n",
    "# & (df['hw13'] <= 0) & (df['b16'] != 0) & (df['v447'] <= 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Remove NaN and infinite values\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "df_cleaned = df.dropna(subset=['childage'])\n",
    "df_cleaned = df.dropna(subset=['hta'])\n",
    "df_cleaned = df.dropna(subset=['wta'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "df_cleaned.to_csv('cleaned_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
